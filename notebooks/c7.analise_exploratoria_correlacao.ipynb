{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entendimento do Problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Objetivo do Problema:\n",
    "- 1.0. Previsao do primeiro destino que um novo usuário irá escolher.\n",
    "    - Porque?\n",
    "    - Qual tipo de modelo de negócio do Airbnb?\n",
    "        - Marketplace (Conectar pessoas que oferecem acomodacao, com pessoas que estao procurando acomodacao)\n",
    "        - Oferta (pessoas oferecendo acomodacao)\n",
    "            - Tamanho do portfólio.\n",
    "            - Diversidade/Densidade de Portfólio.\n",
    "            - Preco Medio\n",
    "            \n",
    "        - Demanda (pessoas procurando acomodacao)\n",
    "            - Numero de Usuários\n",
    "            - LTV (Lifetime Value)\n",
    "            - CAC (Client Acquisition Cost)\n",
    "            \n",
    "            \n",
    "           Gross Revenue = (Fee*Numero cliente) - CAC \n",
    "\n",
    "- Proposta da Solucao\n",
    "- Modelo de Predivao do primeiro destino de um novo usario.\n",
    "- 1.0. Predicoes e salva em tabela do banco de dados. \n",
    "- 2.0. API \n",
    "    - Input: usuario e suas caracteristicas\n",
    "    - Output: usuario e suas caracteristicas com a **predicao do destino**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0.0 Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import random\n",
    "from sklearn import model_selection as ms\n",
    "from sklearn import preprocessing as pp\n",
    "from sklearn import metrics as m\n",
    "from scikitplot import metrics as mt\n",
    "from scipy import stats as ss\n",
    "\n",
    "from keras import models as ml\n",
    "from keras import layers as l\n",
    "\n",
    "from imblearn import under_sampling as us\n",
    "from imblearn import over_sampling as oversamp\n",
    "from imblearn import combine as c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  0.1. Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cramer_v(x, y):\n",
    "    cm = pd.crosstab(x, y).values\n",
    "    n = cm.sum()\n",
    "    r, k = cm.shape\n",
    "    \n",
    "    chi2 = ss.chi2_contingency(cm)[0]\n",
    "    chi2corr = max(0, chi2 - (k-1)*(r-1)/(n-1))\n",
    "    \n",
    "    kcorr = k - (k-1)**2/(n-1)\n",
    "    rcorr = r - (r-1)**2/(n-1)\n",
    "    \n",
    "    return np.sqrt((chi2corr/n) / (min(kcorr-1, rcorr-1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  0.2. Carregando dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = pd.read_csv('../dados/train_users_2.csv', low_memory=True)\n",
    "df_raw.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions = pd.read_csv('../dados/sessions.csv', low_memory=True)\n",
    "df_sessions.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1.0. Descrição dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1 = df_raw.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1. Dimensão dos Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Usuários Número de Linhas: {}'.format(df1.shape[0]))\n",
    "print('Usuários Número de Colunas: {}'.format(df1.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Usuários Número de Linhas: {}'.format(df_sessions.shape[0]))\n",
    "print('Usuários Número de Colunas: {}'.format(df_sessions.shape[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  1.2. Tipo Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3. Check NA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum() / len(df1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions.isna().sum() / len(df_sessions) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Usuário\n",
    "\n",
    "# date_first_booking_max\n",
    "date_first_booking_max = pd.to_datetime(df1['date_first_booking']).max().strftime('%Y-%m-%d')\n",
    "df1['date_first_booking'] = df1['date_first_booking'].fillna(date_first_booking_max)\n",
    "\n",
    "# age\n",
    "df1 = df1[(df1['age'] > 15) & (df1['age'] < 120)]\n",
    "avg_age = df1['age'].mean().astype(int)\n",
    "df1['age'] = df1['age'].fillna(avg_age)\n",
    "\n",
    "# first_affiliate_tracked\n",
    "df1 = df1[~df1['first_affiliate_tracked'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataset Sessions\n",
    "# user_id - 0.3%\n",
    "df_sessions = df_sessions[~df_sessions['user_id'].isna()]\n",
    "\n",
    "# action - 0.7%\n",
    "df_sessions = df_sessions[~df_sessions['action'].isna()]\n",
    "\n",
    "# action_type - 11%\n",
    "df_sessions = df_sessions[~df_sessions['action_type'].isna()]\n",
    "\n",
    "# action_detail - 11%\n",
    "df_sessions = df_sessions[~df_sessions['action_detail'].isna()]\n",
    "\n",
    "# secs_elapsed - 1.2%\n",
    "df_sessions = df_sessions[~df_sessions['secs_elapsed'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.isna().sum() / len(df1) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sessions.isna().sum() / len(df_sessions) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4. Mudando dTyepes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # date_account_created\n",
    "df1['date_account_created'] = pd.to_datetime(df1['date_account_created'])\n",
    "\n",
    "# timestamp_first_active\n",
    "df1['timestamp_first_active'] = pd.to_datetime(df1['timestamp_first_active'], format='%Y%m%d%H%M%S')\n",
    "\n",
    "# date_first_booking\n",
    "df1['date_first_booking'] = pd.to_datetime(df1['date_first_booking'])\n",
    "\n",
    "# age\n",
    "df1['age'] = df1['age'].astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5. Valida Balanceamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df1['country_destination'].value_counts(normalize=True) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6. Análise descritiva"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Users\n",
    "num_attributes = df1.select_dtypes(include=['int64', 'float64', 'int32'])\n",
    "cat_attributes = df1.select_dtypes(exclude=['int64', 'float64', 'datetime64[ns]', 'int32'])\n",
    "time_attributes = df1.select_dtypes(include=['datetime64[ns]'])\n",
    "\n",
    "# Sessions\n",
    "num_attributes_sessions = df_sessions.select_dtypes(include=['int64', 'float64', 'int32'])\n",
    "cat_attributes_sessions = df_sessions.select_dtypes(exclude=['int64', 'float64', 'datetime64[ns]', 'int32'])\n",
    "time_attributes_sessions = df_sessions.select_dtypes(include=['datetime64[ns]'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_analise_descritiva(df):\n",
    "    d0 = df.describe()\n",
    "    d1 = pd.DataFrame(df.apply(lambda x: x.skew())).T\n",
    "    d2 = pd.DataFrame(df.apply(lambda x: x.kurtosis())).T\n",
    "    d3 = pd.DataFrame(df.apply(lambda x: x.max() - x.min())).T\n",
    "    ct = pd.concat([d0, d3, d1, d2]).T.reset_index()\n",
    "    ct.columns = ['Atributos', 'count', 'mean', 'std', 'min', '25%', '50%', '75%', 'max', 'range', 'skew', 'kurtosis']\n",
    "    return ct"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.1. Númerico - Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analise_descritiva(num_attributes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.2. Númerico - Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "get_analise_descritiva(num_attributes_sessions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.3. Categórico - Users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attributes.drop('id', axis=1).describe() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.6.4. Categórico - Sessions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attributes_sessions.drop('user_id', axis=1).describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_attributes_list = cat_attributes_sessions.drop('user_id', axis=1).columns.tolist()\n",
    "\n",
    "corr_dict = {}\n",
    "for i in range(len (cat_attributes_list)):\n",
    "    corr_list = []\n",
    "    for j in range(len(cat_attributes_list)):\n",
    "        ref = cat_attributes_list[i]\n",
    "        feat = cat_attributes_list[j]\n",
    "        \n",
    "        # correlation\n",
    "        corr = cramer_v(cat_attributes_sessions[ ref ], cat_attributes_sessions[ feat ])\n",
    "        \n",
    "        # append a list\n",
    "        corr_list.append(corr)\n",
    "    \n",
    "    # appende a correlation list for each ref attributs\n",
    "    corr_dict[ ref ] = corr_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp = pd.DataFrame(corr_dict)\n",
    "tmp = tmp.set_index(tmp.columns)\n",
    "sns.heatmap(tmp, annot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.0. Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2 = df1.copy()\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1. Criando Novas Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dias desde o primeiro ativo até a primeira reserva\n",
    "df2['first_active'] = pd.to_datetime(df2['timestamp_first_active'].dt.strftime('%Y-%m-%d'))\n",
    "df2['days_from_frist_active_until_booking'] = (df2['date_first_booking'] - df2['first_active']).apply(lambda x: x.days)\n",
    "\n",
    "# dias desde a primeira ativação até a conta criada\n",
    "df2['days_from_first_active_until_account_created'] = (df2['date_account_created'] - df2['first_active']).apply(lambda x: x.days)\n",
    "\n",
    "# dias desde a criação da conta até a primeira reserva\n",
    "df2['days_from_account_created_until_first_booking'] = (df2['date_first_booking'] - df2['date_account_created']).apply(lambda x: x.days)\n",
    "\n",
    "# ================== Primeira Ativação ==================\n",
    "df2['year_first_active'] = df2['first_active'].dt.year\n",
    "df2['month_fist_active'] = df2['first_active'].dt.month\n",
    "df2['day_first_active'] = df2['first_active'].dt.day\n",
    "df2['day_of_week_first_active'] = df2['first_active'].dt.dayofweek\n",
    "df2['week_of_year_first_active'] = df2['first_active'].dt.isocalendar().week\n",
    "\n",
    "# # ================== Primeira reserva ==================\n",
    "df2['year_first_booking'] = df2['date_first_booking'].dt.year\n",
    "df2['month_first_booking'] = df2['date_first_booking'].dt.month\n",
    "df2['day_first_booking'] = df2['date_first_booking'].dt.day\n",
    "df2['day_of_week_first_booking'] = df2['date_first_booking'].dt.dayofweek\n",
    "df2['week_of_year_first_booking'] = df2['date_first_booking'].dt.isocalendar().week\n",
    "\n",
    "# # ================== Conta Criada =================\n",
    "df2['year_account_created'] = df2['date_account_created'].dt.year\n",
    "df2['month_account_created'] = df2['date_account_created'].dt.month\n",
    "df2['day_account_created'] = df2['date_account_created'].dt.day\n",
    "df2['day_of_week_account_created'] = df2['date_account_created'].dt.dayofweek\n",
    "df2['week_of_year_account_created'] = df2['date_account_created'].dt.isocalendar().week"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3.0. Filtragem Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df3 = df2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Filtragem Linhas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filtrando Idade maior que 15 e menor que 120 anos.\n",
    "df3 = df3[(df3['age'] > 15) & (df3['age'] < 120)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Seleção Colunas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = ['date_account_created', 'date_account_created', 'date_first_booking', 'timestamp_first_active', 'first_active']\n",
    "df3 = df3.drop(cols, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4.0. Preparação Dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = df3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Balanceamento Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder Categorical Variables\n",
    "ohe = pp.OneHotEncoder()\n",
    "\n",
    "# Numerical\n",
    "col_num = df4.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "\n",
    "# Categorical\n",
    "col_cat = df4.select_dtypes(exclude=['int64', 'float64', 'datetime64[ns]']).drop(['id', 'country_destination'], axis=1).columns.tolist()\n",
    "\n",
    "# encoding\n",
    "df4_dummy = pd.DataFrame(ohe.fit_transform(df4[ col_cat]).toarray(), index=df4.index)\n",
    "\n",
    "# join numerical and categorical\n",
    "df42 = pd.concat([df4[col_num], df4_dummy], axis=1)\n",
    "df42.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.1. Random Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " # ratio_balanced\n",
    "ratio_balanced = {'NDF': 10000 }\n",
    "# define sampler\n",
    "undersampling = us.RandomUnderSampler(sampling_strategy=ratio_balanced, random_state=32)\n",
    "\n",
    "# apply sampler\n",
    "X_under, y_under = undersampling.fit_resample(df42, df4['country_destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['country_destination'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_under.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.2. Random Oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ratio_balanced\n",
    "#ratio_balanced = {'NDF': 10000 }\n",
    "\n",
    "# define sampler\n",
    "oversampling = oversamp.RandomOverSampler(sampling_strategy='all', random_state=32)\n",
    "\n",
    "# apply sampler\n",
    "X_over, y_over = oversampling.fit_resample(df42, df4['country_destination'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4['country_destination'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_over.value_counts() "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1.3. SMOTE + TOMEKLINK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratio_balanced =  {'NDF': 54852,\n",
    "                'US':  48057,\n",
    "                'other': 6*7511,\n",
    "                'FR': 12*3669,\n",
    "                'IT': 20*2014,\n",
    "                'GB': 30*1758,\n",
    "                'ES': 30*1685,\n",
    "                'CA': 40*1064,\n",
    "                'DE': 45*841,\n",
    "                'NL': 80*595,\n",
    "                'AU': 85*433,\n",
    "                'PT': 300*157}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## - Como é muito demorado para executar, salvo em arquivo para depois carregar já com SmoteTomek\n",
    "\n",
    "# # define sampler\n",
    "# smt = c.SMOTETomek(sampling_strategy=ratio_balanced, random_state=32, n_jobs=-1)\n",
    "\n",
    "# # apply sampler\n",
    "# X_smt, y_smt = smt.fit_resample(df42, df4['country_destination'])\n",
    "\n",
    "# X_smt.to_csv('../dados/X_SMOTETomek')\n",
    "# y_smt.to_csv('../dados/y_SMOTETomek')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df4['country_destination'].value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_smt.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # numerical data\n",
    "# df43 = X_smt[ col_num ]\n",
    "\n",
    "# # categorical data\n",
    "# df44 = X_smt.drop(col_num, axis=1)\n",
    "# df45 = pd.DataFrame(ohe.inverse_transform(df44), columns=col_cat, index=df44.index)\n",
    "\n",
    "# # join numerical categorical\n",
    "# df46 = pd.concat([df43, df45], axis=1)\n",
    "# df46['country_destination'] = y_smt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## --Dummy variável alvo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_dummy = pd.get_dummies(df4.drop(['id', 'country_destination'], axis=1))\n",
    "df4 = pd.concat([df4[['id', 'country_destination']], df4_dummy], axis=1)\n",
    "\n",
    "# Smote\n",
    "# df4_dummy = pd.get_dummies(df46.drop(['country_destination'], axis=1))\n",
    "# df4 = pd.concat([df4[['country_destination']], df4_dummy], axis=1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0. Análise Exploratória(EDA) - Insights -> Dataset sem balanceamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H0.** Os usuários levem até 3 dias, em média, para fazer o cadastro no site em todos os destinos.\n",
    "\n",
    "**Verdadeira.** Os usuários levam até 3 dias, em média para realizar o cadastro no site em todos os destinos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 12))\n",
    "aux01 = df5[['days_from_first_active_until_account_created', 'country_destination']].groupby('country_destination').mean().reset_index()\n",
    "sns.barplot(x='country_destination', y='days_from_first_active_until_account_created' , data=aux01);\n",
    "plt.ylabel('Average days until Accout Creation');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H1.** O numero de reservas do Airbnb cresce ou decresce ao longo do tempo?\n",
    "\n",
    "**Depende.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25,12))\n",
    "aux01 = df5[df5['country_destination'] != 'NDF']\n",
    "aux01 = aux01[['year_first_booking', 'month_first_booking', 'country_destination']]\\\n",
    "                .groupby(['year_first_booking', 'month_first_booking'])\\\n",
    "                .count() \\\n",
    "                .reset_index()\n",
    "\n",
    "aux01['year-month'] = aux01.apply(lambda x: str(x['year_first_booking']) + '-' + str(x['month_first_booking']), axis=1)\n",
    "\n",
    "sns.barplot(x='year-month', y='country_destination', data=aux01);\n",
    "plt.xticks(rotation=90);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H2.** O numero de reservas total cresce 10% ao ano em todos os anos.\n",
    "\n",
    "**Falsa.** O numero de reservas total cresce 10% ao ao apenas entre 2011 e 2013."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(25, 12))\n",
    "aux01 = df5[(df5['country_destination'] != 'NDF') & (df5['year_first_booking'] < 2015)]\n",
    "aux01 = aux01[['year_first_booking', 'country_destination']].groupby('year_first_booking').count().reset_index()\n",
    "\n",
    "aux01['growth'] = 100*aux01['country_destination'].pct_change()\n",
    "\n",
    "sns.barplot(x='year_first_booking', y='growth', data=aux01);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**H4.** Todos os canais de Marketing geram pelo menos 10% de reservas para todos os destinos.\n",
    "\n",
    "**False.** Nem todos os canais de Marketing geram pelo menos 10% de reservas para todos os destinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "affiliate_list = df5['affiliate_provider'].drop_duplicates().tolist()\n",
    "\n",
    "plt.figure(figsize=(25, 50))\n",
    "for i in range(len(affiliate_list)):\n",
    "    plt.subplot(6, 3, i+1)\n",
    "    df5[df5['affiliate_provider'] == affiliate_list[i]]['country_destination'].value_counts(normalize=True).plot.bar();\n",
    "    plt.title(affiliate_list[i]);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Outras Hipóteses para validar**\n",
    "\n",
    "H04. Usuários do sexo feminino fazem 10% mais reservas para países fora dos USA. \n",
    "\n",
    "H05. O canal de Marketing Google representa 40% das reservas para países fora dos USA. \n",
    "\n",
    "H06. O destino dos USA representam mais de 20% em todos os canais. \n",
    "\n",
    "H07. A idade média das pessoas é de 35 anos em todos os destinos. \n",
    "\n",
    "H08. A porcentagem de usuários que usam o site na lingua inglês-americano para reservar acomodações em qualquer destino é maior que 90% \n",
    "\n",
    "H09. O número de reservas do Airbnb é crescente ou decrescente ao longo dos anos? \n",
    "\n",
    "H10. O número de reservas do Airbnb é crescente ao longo dos anos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5.0. Seleção Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove datas originais pois é inútil para o modelo.\n",
    "# cols_drop = ['date_account_created', 'timestamp_first_active', 'date_first_booking', 'first_active']\n",
    "# df5 = df4.drop(cols_drop, axis=1)\n",
    "\n",
    "df5 = df4.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df5.drop('country_destination', axis=1)\n",
    "y = df5['country_destination'].copy()\n",
    "\n",
    "X_train, X_test, y_train, y_test = ms.train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6.0. Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = X_train.drop('id', axis=1)\n",
    "x_test = X_test.drop('id', axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.1. Baseline "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "country_destination_list = df1['country_destination'].drop_duplicates().sort_values().tolist()\n",
    "k_num = y_test.shape[0]\n",
    "country_destination_weights = df1['country_destination'].value_counts(normalize=True).sort_index().tolist()\n",
    "\n",
    "yhat_random = random.choices(population=country_destination_list,  \n",
    "                             weights=country_destination_weights,\n",
    "                             k=k_num)\n",
    "len(yhat_random)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1.1 Baseline Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Accuracy\n",
    "acc_random = m.accuracy_score(y_test, yhat_random)\n",
    "print('Accuracy: {}'.format(acc_random))\n",
    "\n",
    "# Balanced Accuray\n",
    "balanced_acc_random = m.balanced_accuracy_score(y_test, yhat_random)\n",
    "print('Balanced Accuracy:{}'.format(balanced_acc_random))\n",
    "\n",
    "# Kappa Metrics\n",
    "kappa_random = m.cohen_kappa_score(y_test, yhat_random)\n",
    "print('Kappa Score: {}'.format(kappa_random))\n",
    "\n",
    "# Classification report\n",
    "print(m.classification_report(y_test, yhat_random))\n",
    "\n",
    "# Confusion Matrix\n",
    "mt.plot_confusion_matrix(y_test, yhat_random, normalize=False, figsize=(12,12))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.2. Neural Network MLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ohe = pp.OneHotEncoder()\n",
    "y_train_nn = ohe.fit_transform(y_train.values.reshape(-1, 1)).toarray()\n",
    "\n",
    "# Definição Modelo\n",
    "model = ml.Sequential()\n",
    "model.add(l.Dense(256, input_dim=x_train.shape[1], activation='relu'))\n",
    "model.add(l.Dense(13, activation='softmax'))\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "#Treino\n",
    "model.fit(x_train, y_train_nn, epochs=100, verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 NN Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predição\n",
    "pred_nn = model.predict(x_test)\n",
    "\n",
    "# Inverte predição\n",
    "yhat_nn = ohe.inverse_transform(pred_nn)\n",
    "\n",
    "y_test_nn = y_test.to_numpy()\n",
    "yhat_nn = yhat_nn.reshape(1, -1)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acurácia\n",
    "acc_nn =m.accuracy_score(y_test_nn, yhat_nn)\n",
    "print(f'Acurácia: {acc_nn}')\n",
    "\n",
    "# Balanced Accuray\n",
    "balanced_acc_nn = m.balanced_accuracy_score(y_test_nn, yhat_nn)\n",
    "print('Balanced Accuracy:{}'.format(balanced_acc_nn))\n",
    "\n",
    "# Kappa\n",
    "kappa_nn = m.cohen_kappa_score(y_test_nn, yhat_nn)\n",
    "print('Kappa Score: {}'.format(kappa_nn))\n",
    "\n",
    "# Classification report\n",
    "print(m.classification_report(y_test_nn, yhat_nn))\n",
    "\n",
    "# Matriz de Confusão\n",
    "mt.plot_confusion_matrix(y_test_nn, yhat_nn, normalize=False, figsize=(12,12))\n",
    "\n",
    "# Acurácia: 0.8412426614481409\n",
    "# Balanced Accuracy:0.16665800325744187\n",
    "# Kappa Score: 0.7273389222364827"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Acurácia: 0.7094976164283096\n",
    "\n",
    "Balanced Accuracy:0.09153183873284591\n",
    "\n",
    "Kappa Score: 0.004007337133695277"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2.1 NN Performance - Cross-Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_folds = 5\n",
    "kfold = ms.StratifiedKFold(n_splits=num_folds, shuffle=True, random_state=42)\n",
    "\n",
    "balanced_acc_list = []\n",
    "kappa_acc_list = []\n",
    "\n",
    "i = 1\n",
    "for train_ix, val_ix in kfold.split(x_train, y_train):\n",
    "    print(f'Fold {i}/{num_folds}')\n",
    "\n",
    "    # get fold\n",
    "    x_train_fold = x_train.iloc[train_ix]\n",
    "    y_train_fold = y_train.iloc[train_ix]\n",
    "    \n",
    "    x_val_fold = x_train.iloc[val_ix]\n",
    "    y_val_fold = y_train.iloc[val_ix]\n",
    "\n",
    "    # target hot-encoding\n",
    "    ohe = pp.OneHotEncoder()\n",
    "    y_train_fold_nn = ohe.fit_transform(y_train_fold.values.reshape(-1, 1)).toarray()\n",
    "\n",
    "    # Definição Modelo\n",
    "    model = ml.Sequential()\n",
    "    model.add(l.Dense(512, input_dim=x_train.shape[1], activation='relu'))\n",
    "    model.add(l.Dense(12, activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "    # Treino modelo\n",
    "    model.fit(x_train_fold, y_train_fold_nn, epochs=50, batch_size=32, verbose=0)\n",
    "\n",
    "    # Predição\n",
    "    pred_nn = model.predict(x_val_fold)\n",
    "    yhat_nn = ohe.inverse_transform(pred_nn)\n",
    "    \n",
    "    # Ajusta os dados com reshape\n",
    "    y_test_nn = y_val_fold.to_numpy()\n",
    "    yhat_nn = yhat_nn.reshape(1, -1)[0]\n",
    "\n",
    "    # Métricas\n",
    "    ## Balanced Accuracy \n",
    "    balanced_acc_nn = m.balanced_accuracy_score(y_test_nn, yhat_nn)\n",
    "    balanced_acc_list.append(balanced_acc_nn)\n",
    "    \n",
    "    ## Kappa Metrics\n",
    "    kappa_acc_nn = m.cohen_kappa_score(y_test_nn, yhat_nn)\n",
    "    kappa_acc_list.append(kappa_acc_nn)\n",
    "    \n",
    "    i += 1   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Avg Balanced Accuracy: {} +/- {}'.format(np.round(np.mean(balanced_acc_list), 2), \n",
    "                                                  np.round(np.std(balanced_acc_list), 4)))\n",
    "print('Avg Kappa: {} +/- {}'.format(np.round(np.mean(kappa_acc_list), 4), \n",
    "                                      np.round(np.std(kappa_acc_list), 4)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Avg Balanced Accuracy: 0.09 +/- 0.0003\n",
    "\n",
    "Avg Kappa: 0.003 +/- 0.0018"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pa000')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "412216976153f08accfd66da1eb798228bfe83527efcfc9e66487192375cf831"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
